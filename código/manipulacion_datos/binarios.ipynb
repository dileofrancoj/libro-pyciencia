{"cells": [{"cell_type": "markdown", "id": "f9cddaab", "metadata": {}, "source": ["## Uso simple"]}, {"cell_type": "code", "execution_count": 1, "id": "99a6fcac", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["b'abcd\\x01\\x02\\x03\\x04'\n"]}], "source": ["some_bytes = b\"abcd\\x01\\x02\\x03\\x04\"\n", "\n", "with open(\"/tmp/archivoprueba\", \"wb\") as fh:\n", "    fh.write(some_bytes)\n", "\n", "with open(\"/tmp/archivoprueba\", \"rb\") as fh:\n", "    print(fh.read())"]}, {"cell_type": "code", "execution_count": 2, "id": "7492b485", "metadata": {}, "outputs": [{"data": {"text/plain": ["b'ab'"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["fh = open(\"/tmp/archivoprueba\", \"rb\")\n", "# leemos dos bytes\n", "fh.read(2)"]}, {"cell_type": "code", "execution_count": 3, "id": "22c07170", "metadata": {}, "outputs": [{"data": {"text/plain": ["2"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["# vemos donde est\u00e1 el puntero\n", "fh.tell()"]}, {"cell_type": "code", "execution_count": 4, "id": "c7c56abd", "metadata": {}, "outputs": [{"data": {"text/plain": ["b'cd\\x01'"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["# leemos tres bytes m\u00e1s\n", "fh.read(3)"]}, {"cell_type": "code", "execution_count": 5, "id": "40abef0c", "metadata": {}, "outputs": [{"data": {"text/plain": ["b'\\x02\\x03\\x04'"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["# leemos hasta el final\n", "fh.read()"]}, {"cell_type": "code", "execution_count": 6, "id": "c0f95f0a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["b'\\x01\\x02'\n"]}], "source": ["with open(\"/tmp/archivoprueba\", \"rb\") as fh:\n", "    # vamos hasta la cuarta posici\u00f3n\n", "    fh.seek(4)\n", "    # leemos\n", "    print(fh.read(2))"]}, {"cell_type": "code", "execution_count": 7, "id": "fbb6db37", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["b'\\x03\\x04'\n"]}], "source": ["import os\n", "\n", "with open(\"/tmp/archivoprueba\", \"rb\") as fh:\n", "    # leemos los \u00faltimos dos bytes\n", "    fh.seek(-2, os.SEEK_END)\n", "    print(fh.read())"]}, {"cell_type": "code", "execution_count": 8, "id": "3c01cffc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["(debug: text_bytes=b'A\\xc3\\xb1os')\n", "(debug: numbers=[2019, 2023, 2018, 2005, 1993, 1995, 2006])\n", "A\u00f1os: 2019, 2023, 2018, 2005, 1993, 1995, 2006\n"]}], "source": ["# escribimos la secuencia que vamos a leer\n", "sequence = (\n", "    b\"\\x05\\x07A\\xc3\\xb1os\"\n", "    b\"\\x00\\x00\\x07\\xe3\\x00\\x00\\x07\\xe7\"\n", "    b\"\\x00\\x00\\x07\\xe2\\x00\\x00\\x07\\xd5\"\n", "    b\"\\x00\\x00\\x07\\xc9\\x00\\x00\\x07\\xcb\"\n", "    b\"\\x00\\x00\\x07\\xd6\"\n", ")\n", "with open(\"/tmp/archivoprueba\", \"wb\") as fh:\n", "    fh.write(sequence)\n", "\n", "# leemos e interpretamos los bytes del archivo\n", "with open(\"/tmp/archivoprueba\", \"rb\") as fh:\n", "    len_text = int.from_bytes(fh.read(1), byteorder=\"big\")\n", "    quant_numbers = int.from_bytes(fh.read(1), byteorder=\"big\")\n", "    text_bytes = fh.read(len_text)\n", "    print(f\"(debug: {text_bytes=})\")\n", "    numbers = []\n", "    for _ in range(quant_numbers):\n", "        number = int.from_bytes(fh.read(4), byteorder=\"big\")\n", "        numbers.append(number)\n", "    print(f\"(debug: {numbers=})\")\n", "\n", "text = text_bytes.decode(\"utf8\")\n", "num_sequence = ', '.join(map(str, numbers))\n", "print(f\"{text}: {num_sequence}\")"]}, {"cell_type": "code", "execution_count": 9, "id": "7ce59288", "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["(debug: text_bytes=b'A\\xc3\\xb1os')\n", "(debug: numbers=[2019, 2023, 2018, 2005, 1993, 1995, 2006])\n", "A\u00f1os: 2019, 2023, 2018, 2005, 1993, 1995, 2006\n"]}], "source": ["import struct\n", "\n", "with open(\"/tmp/archivoprueba\", \"rb\") as fh:\n", "    len_text, quant_numbers = struct.unpack(\"BB\", fh.read(2))\n", "    complex_format = f\">{len_text}s{quant_numbers}i\"\n", "    text_bytes, *numbers = struct.unpack(complex_format, fh.read())\n", "    print(f\"(debug: {text_bytes=})\")\n", "    print(f\"(debug: {numbers=})\")\n", "\n", "text = text_bytes.decode(\"utf8\")\n", "num_sequence = ', '.join(map(str, numbers))\n", "print(f\"{text}: {num_sequence}\")"]}, {"cell_type": "code", "execution_count": 10, "id": "2ef2a1ed", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Chunk b'IHDR' len=13\n", "    width=1280 height=640\n", "Chunk b'pHYs' len=9\n", "Chunk b'tEXt' len=25\n", "Chunk b'IDAT' len=8192\n", "Chunk b'IDAT' len=8192\n", "Chunk b'IDAT' len=8192\n", "Chunk b'IDAT' len=8192\n", "Chunk b'IDAT' len=1393\n", "Chunk b'IEND' len=0\n"]}], "source": ["from collections import namedtuple\n", "\n", "IHDR_struct = '>IIbbbbb'\n", "IHDR = namedtuple('IHDR', 'width height bit_depth color_type compression filter interlace')\n", "\n", "with open(\"logo.png\", \"rb\") as fh:\n", "    header = fh.read(8)\n", "    assert header == b\"\\x89PNG\\r\\n\\x1A\\n\"\n", "\n", "    while True:\n", "        octet = fh.read(8)\n", "        if not octet:\n", "            break\n", "        length, chunk_type = struct.unpack(\">I4s\", octet)\n", "        print(f\"Chunk {chunk_type!r} len={length}\")\n", "        chunk_data = fh.read(length)\n", "        if chunk_type == b\"IHDR\":\n", "            ihdr = IHDR._make(struct.unpack(IHDR_struct, chunk_data))\n", "            print(f\"    width={ihdr.width} height={ihdr.height}\")\n", "\n", "        fh.read(4)  # CRC, not for this example\n"]}, {"cell_type": "markdown", "id": "f4cd70bb", "metadata": {}, "source": ["## Trabajando con HDF5"]}, {"cell_type": "code", "execution_count": 11, "id": "1a430e63", "metadata": {}, "outputs": [{"data": {"text/plain": ["<KeysViewHDF5 ['datetime', 'latitude', 'longitude', 'mean', 'n', 'std', 'wk']>"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["import h5py\n", "\n", "fh = h5py.File(\"all.h5\", \"r\")\n", "fh.keys()"]}, {"cell_type": "code", "execution_count": 12, "id": "4d3bdbf7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<HDF5 dataset \"datetime\": shape (1, 61368), type \"|S14\">\n", "<HDF5 dataset \"latitude\": shape (581777,), type \"<f4\">\n", "<HDF5 dataset \"longitude\": shape (581777,), type \"<f4\">\n", "<HDF5 dataset \"mean\": shape (581777, 1), type \"<f4\">\n", "<HDF5 dataset \"n\": shape (581777, 1), type \"<i4\">\n", "<HDF5 dataset \"std\": shape (581777, 1), type \"<f4\">\n", "<HDF5 dataset \"wk\": shape (581777, 1), type \"<f4\">\n"]}], "source": ["for dataset in fh.values():\n", "    print(dataset)"]}, {"cell_type": "code", "execution_count": 20, "id": "a8d0a41c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["datetime: [b'20110801230000' b'20110801220000' b'20110801210000' ...\n", " b'20110402020000' b'20110402010000' b'20110402000000']\n", "latitude: 24.026184\n", "mean: [7.5135026]\n"]}, {"data": {"text/plain": ["array([24.01368 , 24.014069, 24.01445 , 24.014832, 24.01519 , 24.015564,\n", "       24.015923, 24.016289, 24.016632, 24.01699 , 24.017326, 24.017662,\n", "       24.018005, 24.018349, 24.01867 , 24.018997, 24.019302, 24.019623,\n", "       24.019936, 24.020256], dtype=float32)"]}, "execution_count": 20, "metadata": {}, "output_type": "execute_result"}], "source": ["print(\"datetime:\", fh[\"datetime\"][0])  # el primer elemento tiene todo el array\n", "print(\"latitude:\", fh[\"latitude\"][42])  # aqu\u00ed lo tenemos directamente\n", "print(\"mean:\", fh[\"mean\"][123])  # y ac\u00e1 cada valor est\u00e1 dentro de una lista\n", "\n", "fh[\"latitude\"][:20]"]}, {"cell_type": "code", "execution_count": 14, "id": "5557d802", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Dimensiones sin nombre:\n", "     <\"\" dimension 0 of HDF5 dataset at 140651888741488>\n", "     <\"\" dimension 1 of HDF5 dataset at 140651888741488>\n", "Tampoco hay atributos: 0\n"]}], "source": ["print(\"Dimensiones sin nombre:\")\n", "for dim in fh[\"mean\"].dims:\n", "    print(\"    \", dim)\n", "print(\"Tampoco hay atributos:\", len(fh[\"latitude\"].attrs))"]}, {"cell_type": "code", "execution_count": 15, "id": "e836c2e3", "metadata": {"scrolled": true}, "outputs": [{"data": {"text/plain": ["array([24.01368 , 24.014069, 24.01445 , ..., 49.291092, 49.283897,\n", "       49.27669 ], dtype=float32)"]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["import numpy as np\n", "\n", "latitudes = np.array(fh[\"latitude\"])\n", "latitudes"]}, {"cell_type": "code", "execution_count": 16, "id": "28a8d13b", "metadata": {}, "outputs": [{"data": {"text/plain": ["52402"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["lat_27 = (latitudes >= 27) & (latitudes < 28)\n", "np.count_nonzero(lat_27)"]}, {"cell_type": "code", "execution_count": 17, "id": "f71a804a", "metadata": {}, "outputs": [{"data": {"text/plain": ["array([7.4238734, 7.4596395, 7.5191693, ..., 9.926428 , 9.930207 ,\n", "       9.933213 ], dtype=float32)"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": ["means = np.squeeze(fh[\"mean\"])\n", "means"]}, {"cell_type": "code", "execution_count": 18, "id": "0a662aec", "metadata": {}, "outputs": [{"data": {"text/plain": ["6.9832783"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": ["means[lat_27].mean()"]}, {"cell_type": "code", "execution_count": 12, "id": "ac8607bb", "metadata": {}, "outputs": [{"data": {"text/plain": ["<class 'netCDF4._netCDF4.Dataset'>\n", "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n", "    CVS_Id: $Id$\n", "    creation_date: \n", "    prg_ID: Source file unknown Version unknown Date unknown\n", "    cmd_ln: bds -x 256 -y 128 -m 23 -o /data/zender/data/dst_T85.nc\n", "    history: Tue Oct 25 15:08:51 2005: ncks -O -x -v va -m sresa1b_ncar_ccsm3_0_run1_200001.nc sresa1b_ncar_ccsm3_0_run1_200001.nc\n", "Tue Oct 25 15:07:21 2005: ncks -d time,0 sresa1b_ncar_ccsm3_0_run1_200001_201912.nc sresa1b_ncar_ccsm3_0_run1_200001.nc\n", "Tue Oct 25 13:29:43 2005: ncks -d time,0,239 sresa1b_ncar_ccsm3_0_run1_200001_209912.nc /var/www/html/tmp/sresa1b_ncar_ccsm3_0_run1_200001_201912.nc\n", "Thu Oct 20 10:47:50 2005: ncks -A -v va /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/sresa1b_ncar_ccsm3_0_run1_va_200001_209912.nc /data/brownmc/sresa1b/atm/mo/tas/ncar_ccsm3_0/run1/sresa1b_ncar_ccsm3_0_run1_200001_209912.nc\n", "Wed Oct 19 14:55:04 2005: ncks -F -d time,01,1200 /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/sresa1b_ncar_ccsm3_0_run1_va_200001_209912.nc /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/sresa1b_ncar_ccsm3_0_run1_va_200001_209912.nc\n", "Wed Oct 19 14:53:28 2005: ncrcat /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/foo_05_1200.nc /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/foo_1192_1196.nc /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/sresa1b_ncar_ccsm3_0_run1_va_200001_209912.nc\n", "Wed Oct 19 14:50:38 2005: ncks -F -d time,05,1200 /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/va_A1.SRESA1B_1.CCSM.atmm.2000-01_cat_2099-12.nc /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/foo_05_1200.nc\n", "Wed Oct 19 14:49:45 2005: ncrcat /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/va_A1.SRESA1B_1.CCSM.atmm.2000-01_cat_2079-12.nc /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/va_A1.SRESA1B_1.CCSM.atmm.2080-01_cat_2099-12.nc /data/brownmc/sresa1b/atm/mo/va/ncar_ccsm3_0/run1/va_A1.SRESA1B_1.CCSM.atmm.2000-01_cat_2099-12.nc\n", "Created from CCSM3 case b30.040a\n", " by wgstrand@ucar.edu\n", " on Wed Nov 17 14:12:57 EST 2004\n", " \n", " For all data, added IPCC requested metadata\n", "    table_id: Table A1\n", "    title: model output prepared for IPCC AR4\n", "    institution: NCAR (National Center for Atmospheric \n", "Research, Boulder, CO, USA)\n", "    source: CCSM3.0, version beta19 (2004): \n", "atmosphere: CAM3.0, T85L26;\n", "ocean     : POP1.4.3 (modified), gx1v3\n", "sea ice   : CSIM5.0, T85;\n", "land      : CLM3.0, gx1v3\n", "    contact: ccsm@ucar.edu\n", "    project_id: IPCC Fourth Assessment\n", "    Conventions: CF-1.0\n", "    references: Collins, W.D., et al., 2005:\n", " The Community Climate System Model, Version 3\n", " Journal of Climate\n", " \n", " Main website: http://www.ccsm.ucar.edu\n", "    acknowledgment:  Any use of CCSM data should acknowledge the contribution\n", " of the CCSM project and CCSM sponsor agencies with the \n", " following citation:\n", " 'This research uses data provided by the Community Climate\n", " System Model project (www.ccsm.ucar.edu), supported by the\n", " Directorate for Geosciences of the National Science Foundation\n", " and the Office of Biological and Environmental Research of\n", " the U.S. Department of Energy.'\n", "In addition, the words 'Community Climate System Model' and\n", " 'CCSM' should be included as metadata for webpages referencing\n", " work using CCSM data or as keywords provided to journal or book\n", "publishers of your manuscripts.\n", "Users of CCSM data accept the responsibility of emailing\n", " citations of publications of research using CCSM data to\n", " ccsm@ucar.edu.\n", "Any redistribution of CCSM data must include this data\n", " acknowledgement statement.\n", "    realization: 1\n", "    experiment_id: 720 ppm stabilization experiment (SRESA1B)\n", "    comment: This simulation was initiated from year 2000 of \n", " CCSM3 model run b30.030a and executed on \n", " hardware cheetah.ccs.ornl.gov. The input external forcings are\n", "ozone forcing    : A1B.ozone.128x64_L18_1991-2100_c040528.nc\n", "aerosol optics   : AerosolOptics_c040105.nc\n", "aerosol MMR      : AerosolMass_V_128x256_clim_c031022.nc\n", "carbon scaling   : carbonscaling_A1B_1990-2100_c040609.nc\n", "solar forcing    : Fixed at 1366.5 W m-2\n", "GHGs             : ghg_ipcc_A1B_1870-2100_c040521.nc\n", "GHG loss rates   : noaamisc.r8.nc\n", "volcanic forcing : none\n", "DMS emissions    : DMS_emissions_128x256_clim_c040122.nc\n", "oxidants         : oxid_128x256_L26_clim_c040112.nc\n", "SOx emissions    : SOx_emissions_A1B_128x256_L2_1990-2100_c040608.nc\n", " Physical constants used for derived data:\n", " Lv (latent heat of evaporation): 2.501e6 J kg-1\n", " Lf (latent heat of fusion     ): 3.337e5 J kg-1\n", " r[h2o] (density of water      ): 1000 kg m-3\n", " g2kg   (grams to kilograms    ): 1000 g kg-1\n", " \n", " Integrations were performed by NCAR and CRIEPI with support\n", " and facilities provided by NSF, DOE, MEXT and ESC/JAMSTEC.\n", "    model_name_english: NCAR CCSM\n", "    dimensions(sizes): lat(128), lon(256), bnds(2), plev(17), time(1)\n", "    variables(dimensions): float32 area(lat, lon), float32 lat(lat), float64 lat_bnds(lat, bnds), float32 lon(lon), float64 lon_bnds(lon, bnds), int32 msk_rgn(lat, lon), float64 plev(plev), float32 pr(time, lat, lon), float32 tas(time, lat, lon), float64 time(time), float64 time_bnds(time, bnds), float32 ua(time, plev, lat, lon)\n", "    groups: "]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["from netCDF4 import Dataset\n", "rootgrp = Dataset(\"sresa1b_ncar_ccsm3-example.nc\", \"r\")\n", "rootgrp"]}, {"cell_type": "code", "execution_count": null, "id": "b8cacbe9", "metadata": {}, "outputs": [], "source": ["from netCDF4 import Dataset\n", "rootgrp = Dataset(\"test\".nc\", \"w\")\n", "rootgrp"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "### Copyright 2020-2023 Facundo Batista y Manuel Carlevaro\n", "\n", "Licencia CC BY-NC-SA 4.0\n", "\n", "Para m\u00e1s info visitar: https://github.com/facundobatista/libro-pyciencia/\n", "\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.6"}}, "nbformat": 4, "nbformat_minor": 5}